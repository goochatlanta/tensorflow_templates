{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57knM8jrYZ2t"
      },
      "source": [
        "# Lab 1: Intro to TensorFlow \n",
        "In this lab, you'll get exposure to using TensorFlow and learn how it can be used for solving deep learning tasks. Go through the code and run each cell. Along the way, you'll encounter several ***TODO*** blocks -- follow the instructions to fill them out before running those cells and continuing.\n",
        "\n",
        "\n",
        "# Part 1: Intro to TensorFlow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'PolyCollection:kwdoc'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m~/.conda/envs/cs4321/lib/python3.9/site-packages/matplotlib/docstring.py:61\u001b[0m, in \u001b[0;36m_ArtistKwdocLoader.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mcls\u001b[39m, \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m _recursive_subclasses(Artist)\n\u001b[1;32m     62\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m name]\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 1)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000039vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/cs4321/lib/python3.9/site-packages/matplotlib/pyplot.py:57\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m docstring\n\u001b[1;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase, MouseButton\n\u001b[0;32m---> 57\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfigure\u001b[39;00m \u001b[39mimport\u001b[39;00m Figure, figaspect\n\u001b[1;32m     58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgridspec\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSpec, SubplotSpec\n\u001b[1;32m     59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m rcParams, rcParamsDefault, get_backend, rcParamsOrig\n",
            "File \u001b[0;32m~/.conda/envs/cs4321/lib/python3.9/site-packages/matplotlib/figure.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _blocking_input, docstring, projections\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39martist\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     Artist, allow_rasterization, _finalize_rasterization)\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
            "File \u001b[0;32m~/.conda/envs/cs4321/lib/python3.9/site-packages/matplotlib/projections/__init__.py:55\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mNon-separable transforms that map from data space to screen space.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m`matplotlib.projections.polar` may also be of interest.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m axes, docstring\n\u001b[1;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeo\u001b[39;00m \u001b[39mimport\u001b[39;00m AitoffAxes, HammerAxes, LambertAxes, MollweideAxes\n\u001b[1;32m     57\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpolar\u001b[39;00m \u001b[39mimport\u001b[39;00m PolarAxes\n",
            "File \u001b[0;32m~/.conda/envs/cs4321/lib/python3.9/site-packages/matplotlib/axes/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_subplots\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_axes\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "File \u001b[0;32m~/.conda/envs/cs4321/lib/python3.9/site-packages/matplotlib/axes/_subplots.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, cbook\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maxes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_axes\u001b[39;00m \u001b[39mimport\u001b[39;00m Axes\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgridspec\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSpec, SubplotSpec\n\u001b[1;32m      7\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSubplotBase\u001b[39;00m:\n",
            "File \u001b[0;32m~/.conda/envs/cs4321/lib/python3.9/site-packages/matplotlib/axes/_axes.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpatches\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpatches\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpath\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquiver\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmquiver\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstackplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmstack\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstreamplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmstream\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/cs4321/lib/python3.9/site-packages/matplotlib/quiver.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmtext\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m _quiver_doc \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[39mPlot a 2D field of arrows.\u001b[39;49m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39mCall signature::\u001b[39;49m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[39m  quiver([X, Y], U, V, [C], **kw)\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[39m*X*, *Y* define the arrow locations, *U*, *V* define the arrow directions, and\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[39m*C* optionally sets the color.\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[39mEach arrow is internally represented by a filled polygon with a default edge\u001b[39;49m\n\u001b[1;32m     41\u001b[0m \u001b[39mlinewidth of 0. As a result, an arrow is rather a filled area, not a line with\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[39ma head, and `.PolyCollection` properties like *linewidth*, *linestyle*,\u001b[39;49m\n\u001b[1;32m     43\u001b[0m \u001b[39m*facecolor*, etc. act accordingly.\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[39m**Arrow size**\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[39mThe default settings auto-scales the length of the arrows to a reasonable size.\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[39mTo change this behavior see the *scale* and *scale_units* parameters.\u001b[39;49m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[39m**Arrow shape**\u001b[39;49m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[39mThe defaults give a slightly swept-back arrow; to make the head a\u001b[39;49m\n\u001b[1;32m     53\u001b[0m \u001b[39mtriangle, make *headaxislength* the same as *headlength*. To make the\u001b[39;49m\n\u001b[1;32m     54\u001b[0m \u001b[39marrow more pointed, reduce *headwidth* or increase *headlength* and\u001b[39;49m\n\u001b[1;32m     55\u001b[0m \u001b[39m*headaxislength*. To make the head smaller relative to the shaft,\u001b[39;49m\n\u001b[1;32m     56\u001b[0m \u001b[39mscale down all the head parameters. You will probably do best to leave\u001b[39;49m\n\u001b[1;32m     57\u001b[0m \u001b[39mminshaft alone.\u001b[39;49m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[39m**Arrow outline**\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[39m*linewidths* and *edgecolors* can be used to customize the arrow\u001b[39;49m\n\u001b[1;32m     62\u001b[0m \u001b[39moutlines.\u001b[39;49m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[39mParameters\u001b[39;49m\n\u001b[1;32m     65\u001b[0m \u001b[39m----------\u001b[39;49m\n\u001b[1;32m     66\u001b[0m \u001b[39mX, Y : 1D or 2D array-like, optional\u001b[39;49m\n\u001b[1;32m     67\u001b[0m \u001b[39m    The x and y coordinates of the arrow locations.\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[39m    If not given, they will be generated as a uniform integer meshgrid based\u001b[39;49m\n\u001b[1;32m     70\u001b[0m \u001b[39m    on the dimensions of *U* and *V*.\u001b[39;49m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[39m    If *X* and *Y* are 1D but *U*, *V* are 2D, *X*, *Y* are expanded to 2D\u001b[39;49m\n\u001b[1;32m     73\u001b[0m \u001b[39m    using ``X, Y = np.meshgrid(X, Y)``. In this case ``len(X)`` and ``len(Y)``\u001b[39;49m\n\u001b[1;32m     74\u001b[0m \u001b[39m    must match the column and row dimensions of *U* and *V*.\u001b[39;49m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[39mU, V : 1D or 2D array-like\u001b[39;49m\n\u001b[1;32m     77\u001b[0m \u001b[39m    The x and y direction components of the arrow vectors.\u001b[39;49m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[39m    They must have the same number of elements, matching the number of arrow\u001b[39;49m\n\u001b[1;32m     80\u001b[0m \u001b[39m    locations. *U* and *V* may be masked. Only locations unmasked in\u001b[39;49m\n\u001b[1;32m     81\u001b[0m \u001b[39m    *U*, *V*, and *C* will be drawn.\u001b[39;49m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[39mC : 1D or 2D array-like, optional\u001b[39;49m\n\u001b[1;32m     84\u001b[0m \u001b[39m    Numeric data that defines the arrow colors by colormapping via *norm* and\u001b[39;49m\n\u001b[1;32m     85\u001b[0m \u001b[39m    *cmap*.\u001b[39;49m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[39m    This does not support explicit colors. If you want to set colors directly,\u001b[39;49m\n\u001b[1;32m     88\u001b[0m \u001b[39m    use *color* instead.  The size of *C* must match the number of arrow\u001b[39;49m\n\u001b[1;32m     89\u001b[0m \u001b[39m    locations.\u001b[39;49m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[39munits : \u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwidth\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mheight\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdots\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minches\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mxy\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m}, default: \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwidth\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     92\u001b[0m \u001b[39m    The arrow dimensions (except for *length*) are measured in multiples of\u001b[39;49m\n\u001b[1;32m     93\u001b[0m \u001b[39m    this unit.\u001b[39;49m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[39m    The following values are supported:\u001b[39;49m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[39m    - \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwidth\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mheight\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m: The width or height of the axis.\u001b[39;49m\n\u001b[1;32m     98\u001b[0m \u001b[39m    - \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdots\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minches\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m: Pixels or inches based on the figure dpi.\u001b[39;49m\n\u001b[1;32m     99\u001b[0m \u001b[39m    - \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mxy\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m: *X*, *Y* or :math:`\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39msqrt\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39mX^2 + Y^2}` in data units.\u001b[39;49m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[39m    The arrows scale differently depending on the units.  For\u001b[39;49m\n\u001b[1;32m    102\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m or \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, the arrows get larger as one zooms in; for other\u001b[39;49m\n\u001b[1;32m    103\u001b[0m \u001b[39m    units, the arrow size is independent of the zoom state.  For\u001b[39;49m\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwidth or \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mheight\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, the arrow size increases with the width and\u001b[39;49m\n\u001b[1;32m    105\u001b[0m \u001b[39m    height of the axes, respectively, when the window is resized;\u001b[39;49m\n\u001b[1;32m    106\u001b[0m \u001b[39m    for \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdots\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m or \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minches\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, resizing does not change the arrows.\u001b[39;49m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[39mangles : \u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39muv\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mxy\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m} or array-like, default: \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39muv\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    109\u001b[0m \u001b[39m    Method for determining the angle of the arrows.\u001b[39;49m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[39m    - \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39muv\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m: The arrow axis aspect ratio is 1 so that\u001b[39;49m\n\u001b[1;32m    112\u001b[0m \u001b[39m      if *U* == *V* the orientation of the arrow on the plot is 45 degrees\u001b[39;49m\n\u001b[1;32m    113\u001b[0m \u001b[39m      counter-clockwise from the horizontal axis (positive to the right).\u001b[39;49m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[39m      Use this if the arrows symbolize a quantity that is not based on\u001b[39;49m\n\u001b[1;32m    116\u001b[0m \u001b[39m      *X*, *Y* data coordinates.\u001b[39;49m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[39m    - \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mxy\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m: Arrows point from (x, y) to (x+u, y+v).\u001b[39;49m\n\u001b[1;32m    119\u001b[0m \u001b[39m      Use this for plotting a gradient field, for example.\u001b[39;49m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[39m    - Alternatively, arbitrary angles may be specified explicitly as an array\u001b[39;49m\n\u001b[1;32m    122\u001b[0m \u001b[39m      of values in degrees, counter-clockwise from the horizontal axis.\u001b[39;49m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[39m      In this case *U*, *V* is only used to determine the length of the\u001b[39;49m\n\u001b[1;32m    125\u001b[0m \u001b[39m      arrows.\u001b[39;49m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[39m    Note: inverting a data axis will correspondingly invert the\u001b[39;49m\n\u001b[1;32m    128\u001b[0m \u001b[39m    arrows only with ``angles=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mxy\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m``.\u001b[39;49m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[39mscale : float, optional\u001b[39;49m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Number of data units per arrow length unit, e.g., m/s per plot width; a\u001b[39;49m\n\u001b[1;32m    132\u001b[0m \u001b[39m    smaller scale parameter makes the arrow longer. Default is *None*.\u001b[39;49m\n\u001b[1;32m    133\u001b[0m \n\u001b[1;32m    134\u001b[0m \u001b[39m    If *None*, a simple autoscaling algorithm is used, based on the average\u001b[39;49m\n\u001b[1;32m    135\u001b[0m \u001b[39m    vector length and the number of vectors. The arrow length unit is given by\u001b[39;49m\n\u001b[1;32m    136\u001b[0m \u001b[39m    the *scale_units* parameter.\u001b[39;49m\n\u001b[1;32m    137\u001b[0m \n\u001b[1;32m    138\u001b[0m \u001b[39mscale_units : \u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwidth\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mheight\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdots\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minches\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mxy\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m}, optional\u001b[39;49m\n\u001b[1;32m    139\u001b[0m \u001b[39m    If the *scale* kwarg is *None*, the arrow length unit. Default is *None*.\u001b[39;49m\n\u001b[1;32m    140\u001b[0m \n\u001b[1;32m    141\u001b[0m \u001b[39m    e.g. *scale_units* is \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minches\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, *scale* is 2.0, and ``(u, v) = (1, 0)``,\u001b[39;49m\n\u001b[1;32m    142\u001b[0m \u001b[39m    then the vector will be 0.5 inches long.\u001b[39;49m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[39m    If *scale_units* is \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwidth\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m or \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mheight\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, then the vector will be half the\u001b[39;49m\n\u001b[1;32m    145\u001b[0m \u001b[39m    width/height of the axes.\u001b[39;49m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[39m    If *scale_units* is \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m then the vector will be 0.5 x-axis\u001b[39;49m\n\u001b[1;32m    148\u001b[0m \u001b[39m    units. To plot vectors in the x-y plane, with u and v having\u001b[39;49m\n\u001b[1;32m    149\u001b[0m \u001b[39m    the same units as x and y, use\u001b[39;49m\n\u001b[1;32m    150\u001b[0m \u001b[39m    ``angles=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mxy\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, scale_units=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mxy\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, scale=1``.\u001b[39;49m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m \u001b[39mwidth : float, optional\u001b[39;49m\n\u001b[1;32m    153\u001b[0m \u001b[39m    Shaft width in arrow units; default depends on choice of units,\u001b[39;49m\n\u001b[1;32m    154\u001b[0m \u001b[39m    above, and number of vectors; a typical starting value is about\u001b[39;49m\n\u001b[1;32m    155\u001b[0m \u001b[39m    0.005 times the width of the plot.\u001b[39;49m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39mheadwidth : float, default: 3\u001b[39;49m\n\u001b[1;32m    158\u001b[0m \u001b[39m    Head width as multiple of shaft width.\u001b[39;49m\n\u001b[1;32m    159\u001b[0m \n\u001b[1;32m    160\u001b[0m \u001b[39mheadlength : float, default: 5\u001b[39;49m\n\u001b[1;32m    161\u001b[0m \u001b[39m    Head length as multiple of shaft width.\u001b[39;49m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[39mheadaxislength : float, default: 4.5\u001b[39;49m\n\u001b[1;32m    164\u001b[0m \u001b[39m    Head length at shaft intersection.\u001b[39;49m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[39mminshaft : float, default: 1\u001b[39;49m\n\u001b[1;32m    167\u001b[0m \u001b[39m    Length below which arrow scales, in units of head length. Do not\u001b[39;49m\n\u001b[1;32m    168\u001b[0m \u001b[39m    set this to less than 1, or small arrows will look terrible!\u001b[39;49m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39mminlength : float, default: 1\u001b[39;49m\n\u001b[1;32m    171\u001b[0m \u001b[39m    Minimum length as a multiple of shaft width; if an arrow length\u001b[39;49m\n\u001b[1;32m    172\u001b[0m \u001b[39m    is less than this, plot a dot (hexagon) of this diameter instead.\u001b[39;49m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39mpivot : \u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtail\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmid\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmiddle\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtip\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m}, default: \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtail\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    175\u001b[0m \u001b[39m    The part of the arrow that is anchored to the *X*, *Y* grid. The arrow\u001b[39;49m\n\u001b[1;32m    176\u001b[0m \u001b[39m    rotates about this point.\u001b[39;49m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmid\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m is a synonym for \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmiddle\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\n\u001b[1;32m    179\u001b[0m \n\u001b[1;32m    180\u001b[0m \u001b[39mcolor : color or color sequence, optional\u001b[39;49m\n\u001b[1;32m    181\u001b[0m \u001b[39m    Explicit color(s) for the arrows. If *C* has been set, *color* has no\u001b[39;49m\n\u001b[1;32m    182\u001b[0m \u001b[39m    effect.\u001b[39;49m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[39m    This is a synonym for the `.PolyCollection` *facecolor* parameter.\u001b[39;49m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[39mOther Parameters\u001b[39;49m\n\u001b[1;32m    187\u001b[0m \u001b[39m----------------\u001b[39;49m\n\u001b[1;32m    188\u001b[0m \u001b[39mdata : indexable object, optional\u001b[39;49m\n\u001b[1;32m    189\u001b[0m \u001b[39m    DATA_PARAMETER_PLACEHOLDER\u001b[39;49m\n\u001b[1;32m    190\u001b[0m \n\u001b[1;32m    191\u001b[0m \u001b[39m**kwargs : `~matplotlib.collections.PolyCollection` properties, optional\u001b[39;49m\n\u001b[1;32m    192\u001b[0m \u001b[39m    All other keyword arguments are passed on to `.PolyCollection`:\u001b[39;49m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[39m    \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m(PolyCollection:kwdoc)s\u001b[39;49m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[39mReturns\u001b[39;49m\n\u001b[1;32m    197\u001b[0m \u001b[39m-------\u001b[39;49m\n\u001b[1;32m    198\u001b[0m \u001b[39m`~matplotlib.quiver.Quiver`\u001b[39;49m\n\u001b[1;32m    199\u001b[0m \n\u001b[1;32m    200\u001b[0m \u001b[39mSee Also\u001b[39;49m\n\u001b[1;32m    201\u001b[0m \u001b[39m--------\u001b[39;49m\n\u001b[1;32m    202\u001b[0m \u001b[39m.Axes.quiverkey : Add a key to a quiver plot.\u001b[39;49m\n\u001b[1;32m    203\u001b[0m \u001b[39m\"\"\"\u001b[39;49m \u001b[39m%\u001b[39;49m docstring\u001b[39m.\u001b[39;49minterpd\u001b[39m.\u001b[39;49mparams\n\u001b[1;32m    205\u001b[0m docstring\u001b[39m.\u001b[39minterpd\u001b[39m.\u001b[39mupdate(quiver_doc\u001b[39m=\u001b[39m_quiver_doc)\n\u001b[1;32m    208\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mQuiverKey\u001b[39;00m(martist\u001b[39m.\u001b[39mArtist):\n",
            "File \u001b[0;32m~/.conda/envs/cs4321/lib/python3.9/site-packages/matplotlib/docstring.py:64\u001b[0m, in \u001b[0;36m_ArtistKwdocLoader.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[39mcls\u001b[39m, \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m _recursive_subclasses(Artist)\n\u001b[1;32m     62\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m name]\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetdefault(key, kwdoc(\u001b[39mcls\u001b[39m))\n",
            "\u001b[0;31mKeyError\u001b[0m: 'PolyCollection:kwdoc'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QNMcdP4m3Vs"
      },
      "source": [
        "## 1.1 Why is TensorFlow called TensorFlow?\n",
        "\n",
        "TensorFlow is called 'TensorFlow' because it handles the flow (node/mathematical operation) of Tensors, which are data structures that you can think of as multi-dimensional arrays. Tensors are represented as n-dimensional arrays of base dataypes such as a string or integer -- they provide a way to generalize vectors and matrices to higher dimensions.\n",
        "\n",
        "The ```shape``` of a Tensor defines its number of dimensions and the size of each dimension. The ```rank``` of a Tensor provides the number of dimensions (n-dimensions) -- you can also think of this as the Tensor's order or degree.\n",
        "\n",
        "Let's first look at 0-d Tensors, of which a scalar is an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tFxztZQInlAB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`sport` is a 0-d Tensor\n",
            "`number` is a 0-d Tensor\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-10 12:15:54.228846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2022-07-10 12:15:54.228906: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-07-10 12:15:54.228943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (submit-0.hamming.cluster): /proc/driver/nvidia/version does not exist\n",
            "2022-07-10 12:15:54.229557: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "sport = tf.constant(\"Tennis\", tf.string)\n",
        "number = tf.constant(1.41421356237, tf.float64)\n",
        "\n",
        "print(\"`sport` is a {}-d Tensor\".format(tf.rank(sport).numpy()))\n",
        "print(\"`number` is a {}-d Tensor\".format(tf.rank(number).numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dljcPUcoJZ6"
      },
      "source": [
        "Vectors and lists can be used to create 1-d Tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oaHXABe8oPcO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`sports` is a 1-d Tensor with shape: [2]\n",
            "`numbers` is a 1-d Tensor with shape: [3]\n"
          ]
        }
      ],
      "source": [
        "sports = tf.constant([\"Tennis\", \"Basketball\"], tf.string)\n",
        "numbers = tf.constant([3.141592, 1.414213, 2.71821], tf.float64)\n",
        "\n",
        "print(\"`sports` is a {}-d Tensor with shape: {}\".format(tf.rank(sports).numpy(), tf.shape(sports)))\n",
        "print(\"`numbers` is a {}-d Tensor with shape: {}\".format(tf.rank(numbers).numpy(), tf.shape(numbers)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvffwkvtodLP"
      },
      "source": [
        "Next we consider creating 2-d (i.e., matrices) and higher-rank Tensors. For examples, in future labs involving image processing and computer vision, we will use 4-d Tensors. Here the dimensions correspond to the number of example images in our batch, image height, image width, and the number of color channels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tFeBBe1IouS3"
      },
      "outputs": [],
      "source": [
        "### Defining higher-order Tensors ###\n",
        "\n",
        "'''Define a 2-d Tensor'''\n",
        "matrix = tf.constant(np.matrix([[2, 5, 3],[4, 1, 2]]), tf.float64)\n",
        "\n",
        "assert isinstance(matrix, tf.Tensor), \"matrix must be a tf Tensor object\"\n",
        "assert tf.rank(matrix).numpy() == 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Zv1fTn_Ya_cz"
      },
      "outputs": [],
      "source": [
        "'''TODO: Define a 4-d Tensor.'''\n",
        "# Use tf.zeros to initialize a 4-d Tensor of zeros with size 10 x 256 x 256 x 3. \n",
        "#   You can think of this as 10 images where each image is RGB 256 x 256.\n",
        "images = tf.zeros([10, 256, 256, 3])\n",
        "\n",
        "assert isinstance(images, tf.Tensor), \"matrix must be a tf Tensor object\"\n",
        "assert tf.rank(images).numpy() == 4, \"matrix must be of rank 4\"\n",
        "assert tf.shape(images).numpy().tolist() == [10, 256, 256, 3], \"matrix is incorrect shape\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkaCDOGapMyl"
      },
      "source": [
        "As you have seen, the ```shape``` of a Tensor provides the number of elements in each Tensor dimension. The ```shape``` is quite useful, and we'll use it often. You can also use slicing to access subtensors within a higher-rank Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FhaufyObuLEG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`row_vector`: [4. 1. 2.]\n",
            "`column_vector`: [3. 2.]\n",
            "`scalar`: 2.0\n"
          ]
        }
      ],
      "source": [
        "row_vector = matrix[1]\n",
        "column_vector = matrix[:,2]\n",
        "scalar = matrix[1, 2]\n",
        "\n",
        "print(\"`row_vector`: {}\".format(row_vector.numpy()))\n",
        "print(\"`column_vector`: {}\".format(column_vector.numpy()))\n",
        "print(\"`scalar`: {}\".format(scalar.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD3VO-LZYZ2z"
      },
      "source": [
        "## 1.2 Computations on Tensors\n",
        "\n",
        "A convenient way to think about and visualize computations in TensorFlow is in terms of graphs. We can define this graph in terms of Tensors, which hold data, and the mathematical operations that act on these Tensors in some order. Let's look at a simple example, and define this computation using TensorFlow:\n",
        "\n",
        "![alt text](img/add-graph.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X_YJrZsxYZ2z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(76, shape=(), dtype=int32)\n",
            "tf.Tensor(76, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Create the nodes in the graph, and initialize values\n",
        "a = tf.constant(15)\n",
        "b = tf.constant(61)\n",
        "\n",
        "# Add them!\n",
        "c1 = tf.add(a,b)\n",
        "c2 = a + b # TensorFlow overrides the \"+\" operation so that it is able to act on Tensors\n",
        "print(c1)\n",
        "print(c2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbfv_QOiYZ23"
      },
      "source": [
        "Notice how we've created a computation graph consisting of TensorFlow operations, and how  the output is a Tensor with value 76 -- we've just created a computation graph consisting of operations, and it's executed them and given us back the result.\n",
        "\n",
        "Now let's consider a slightly more complicated example:\n",
        "\n",
        "![alt text](img/computation-graph.png)\n",
        "\n",
        "Here, we take two inputs, `a, b`, and compute an output `e`. Each node in the graph represents an operation that takes some input, does some computation, and passes its output to another node.\n",
        "\n",
        "Let's define a simple function in TensorFlow to construct this computation function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PJnfzpWyYZ23",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "### Defining Tensor computations ###\n",
        "\n",
        "# Construct a simple computation function\n",
        "def func(a,b):\n",
        "  '''TODO: Define the operation for c, d, e (use tf.add, tf.subtract, tf.multiply).'''\n",
        "  c = tf.add(a, b)\n",
        "  d = b-1\n",
        "  e = tf.multiply(c, d)\n",
        "  return e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwrRfDMS2-oy"
      },
      "source": [
        "Now, we can call this function to execute the computation graph given some inputs `a,b`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pnwsf8w2uF7p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Consider example values for a,b\n",
        "a, b = 1.5, 2.5\n",
        "# Execute the computation\n",
        "e_out = func(a,b)\n",
        "print(e_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HqgUIUhYZ29"
      },
      "source": [
        "Notice how our output is a Tensor with value defined by the output of the computation, and that the output has no shape as it is a single scalar value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h4o9Bb0YZ29"
      },
      "source": [
        "## 1.3 Neural networks in TensorFlow\n",
        "We can also define neural networks in TensorFlow. TensorFlow uses a high-level API called [Keras](https://www.tensorflow.org/guide/keras) that provides a powerful, intuitive framework for building and training deep learning models.\n",
        "\n",
        "Let's first consider the example of a simple perceptron defined by just one dense layer: $ y = \\sigma(Wx + b)$, where $W$ represents a matrix of weights, $b$ is a bias, $x$ is the input, $\\sigma$ is the sigmoid activation function, and $y$ is the output. We can also visualize this operation using a graph: \n",
        "\n",
        "![alt text](img/computation-graph-2.png)\n",
        "\n",
        "Tensors can flow through abstract types called [```Layers```](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) -- the building blocks of neural networks. ```Layers``` implement common neural networks operations, and are used to update weights, compute losses, and define inter-layer connectivity. We will first define a ```Layer``` to implement the simple perceptron defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HutbJk-1kHPh"
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "Matrix size-incompatible: In[0]: [2,3], In[1]: [1,2] [Op:MatMul]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32m/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=28'>29</a>\u001b[0m layer\u001b[39m.\u001b[39mbuild((\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=29'>30</a>\u001b[0m x_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant([[\u001b[39m1\u001b[39m,\u001b[39m2.\u001b[39m]], shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=30'>31</a>\u001b[0m y \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mcall(x_input)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=32'>33</a>\u001b[0m \u001b[39m# test the output!\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mnumpy())\n",
            "\u001b[1;32m/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb Cell 22\u001b[0m in \u001b[0;36mOurDenseLayer.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=19'>20</a>\u001b[0m   \u001b[39m'''TODO: define the operation for z (hint: use tf.matmul)'''\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=20'>21</a>\u001b[0m   z \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmatmul(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW, x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=21'>22</a>\u001b[0m   \u001b[39m'''TODO: define the operation for out (hint: use tf.sigmoid)'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2268616d6d696e672d737562312e75632e6e70732e656475222c2275736572223a22656c697a61626574682e676f6f6368227d/home/elizabeth.gooch/tensorflow_templates/week1/Lab_week1.ipynb#ch0000019vscode-remote?line=22'>23</a>\u001b[0m   y \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msigmoid(z)\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [2,3], In[1]: [1,2] [Op:MatMul]"
          ]
        }
      ],
      "source": [
        "### Defining a network Layer ###\n",
        "\n",
        "# n_output_nodes: number of output nodes\n",
        "# input_shape: shape of the input\n",
        "# x: input to the layer\n",
        "\n",
        "class OurDenseLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, n_output_nodes):\n",
        "    super(OurDenseLayer, self).__init__()\n",
        "    self.n_output_nodes = n_output_nodes\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    d = int(input_shape[-1])\n",
        "    # Define and initialize parameters: a weight matrix W and bias b\n",
        "    # Note that parameter initialization is random!\n",
        "    self.W = self.add_weight(\"weight\", shape=[d, self.n_output_nodes]) # note the dimensionality\n",
        "    self.b = self.add_weight(\"bias\", shape=[1, self.n_output_nodes]) # note the dimensionality\n",
        "\n",
        "  def call(self, x):\n",
        "    '''TODO: define the operation for z (hint: use tf.matmul)'''\n",
        "    z = tf.matmul(self.W, x)\n",
        "    '''TODO: define the operation for out (hint: use tf.sigmoid)'''\n",
        "    y = tf.sigmoid(z)\n",
        "    return y\n",
        "\n",
        "# Since layer parameters are initialized randomly, we will set a random seed for reproducibility\n",
        "tf.random.set_seed(1)\n",
        "layer = OurDenseLayer(3)\n",
        "layer.build((1,2))\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "y = layer.call(x_input)\n",
        "\n",
        "# test the output!\n",
        "print(y.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt1FgM7qYZ3D"
      },
      "source": [
        "Conveniently, TensorFlow has defined a number of ```Layers``` that are commonly used in neural networks, for example a [```Dense```](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?version=stable). Now, instead of using a single ```Layer``` to define our simple neural network, we'll use the  [`Sequential`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Sequential) model from Keras and a single [`Dense` ](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense) layer to define our network. With the `Sequential` API, you can readily create neural networks by stacking together layers like building blocks. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7WXTpmoL6TDz"
      },
      "outputs": [],
      "source": [
        "### Defining a neural network using the Sequential API ###\n",
        "\n",
        "# Import relevant packages\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the number of outputs\n",
        "n_output_nodes = 3\n",
        "\n",
        "# First define the model \n",
        "model = Sequential()\n",
        "\n",
        "'''TODO: Define a dense (fully connected) layer to compute z'''\n",
        "# Remember: dense layers are defined by the parameters W and b!\n",
        "# You can read more about the initialization of W and b in the TF documentation :) \n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?version=stable\n",
        "dense_layer = tf.keras.layers.Dense(n_output_nodes)\n",
        "\n",
        "# Add the dense layer to the model\n",
        "model.add(dense_layer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDGcwYfUyR-U"
      },
      "source": [
        "That's it! We've defined our model using the Sequential API. Now, we can test it out using an example input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "sg23OczByRDb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[ 0.24415088  0.6485772  -1.9461871 ]], shape=(1, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Test model with example input\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "\n",
        "'''TODO: feed input into the model and predict the output!'''\n",
        "model_output = model(x_input)\n",
        "print(model_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596NvsOOtr9F"
      },
      "source": [
        "In addition to defining models using the `Sequential` API, we can also define neural networks by directly subclassing the [`Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=stable) class, which groups layers together to enable model training and inference. The `Model` class captures what we refer to as a \"model\" or as a \"network\". Using Subclassing, we can create a class for our model, and then define the forward pass through the network using the `call` function. Subclassing affords the flexibility to define custom layers, custom training loops, custom activation functions, and custom models. Let's define the same neural network as above now using Subclassing rather than the `Sequential` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4aCflPVyViD"
      },
      "outputs": [],
      "source": [
        "### Defining a model using subclassing ###\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class SubclassModel(tf.keras.Model):\n",
        "\n",
        "  # In __init__, we define the Model's layers\n",
        "  def __init__(self, n_output_nodes):\n",
        "    super(SubclassModel, self).__init__()\n",
        "    '''TODO: Our model consists of a single Dense layer. Define this layer.''' \n",
        "    self.dense_layer = '''TODO: Dense Layer'''\n",
        "\n",
        "  # In the call function, we define the Model's forward pass.\n",
        "  def call(self, inputs):\n",
        "    return self.dense_layer(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0-lwHDk4irB"
      },
      "source": [
        "Just like the model we built using the `Sequential` API, let's test out our `SubclassModel` using an example input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhB34RA-4gXb"
      },
      "outputs": [],
      "source": [
        "n_output_nodes = 3\n",
        "model = SubclassModel(n_output_nodes)\n",
        "\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "\n",
        "print(model.call(x_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTIFMJLAzsyE"
      },
      "source": [
        "Importantly, Subclassing affords us a lot of flexibility to define custom models. For example, we can use boolean arguments in the `call` function to specify different network behaviors, for example different behaviors during training and inference. Let's suppose under some instances we want our network to simply output the input, without any perturbation. We define a boolean argument `isidentity` to control this behavior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7jzGX5D1xT5"
      },
      "outputs": [],
      "source": [
        "### Defining a model using subclassing and specifying custom behavior ###\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class IdentityModel(tf.keras.Model):\n",
        "\n",
        "  # As before, in __init__ we define the Model's layers\n",
        "  # Since our desired behavior involves the forward pass, this part is unchanged\n",
        "  def __init__(self, n_output_nodes):\n",
        "    super(IdentityModel, self).__init__()\n",
        "    self.dense_layer = tf.keras.layers.Dense(n_output_nodes, activation='sigmoid')\n",
        "\n",
        "  '''TODO: Implement the behavior where the network outputs the input, unchanged, \n",
        "      under control of the isidentity argument.'''\n",
        "  def call(self, inputs, isidentity=False):\n",
        "    x = self.dense_layer(inputs)\n",
        "    '''TODO: Implement identity behavior'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku4rcCGx5T3y"
      },
      "source": [
        "Let's test this behavior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzC0mgbk5dp2"
      },
      "outputs": [],
      "source": [
        "n_output_nodes = 3\n",
        "model = IdentityModel(n_output_nodes)\n",
        "\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "'''TODO: pass the input into the model and call with and without the input identity option.'''\n",
        "out_activate = # TODO\n",
        "out_identity = # TODO\n",
        "\n",
        "print(\"Network output with activation: {}; network identity output: {}\".format(out_activate.numpy(), out_identity.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V1dEqdk6VI5"
      },
      "source": [
        "Now that we have learned how to define `Layers` as well as neural networks in TensorFlow using both the `Sequential` and Subclassing APIs, we're ready to turn our attention to how to actually implement network training with backpropagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQwDhKn8kbO2"
      },
      "source": [
        "## 1.4 Automatic differentiation in TensorFlow\n",
        "\n",
        "[Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
        "is one of the most important parts of TensorFlow and is the backbone of training with \n",
        "[backpropagation](https://en.wikipedia.org/wiki/Backpropagation). We will use the TensorFlow GradientTape [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape?version=stable) to trace operations for computing gradients later. \n",
        "\n",
        "When a forward pass is made through the network, all forward-pass operations get recorded to a \"tape\"; then, to compute the gradient, the tape is played backwards. By default, the tape is discarded after it is played backwards; this means that a particular `tf.GradientTape` can only\n",
        "compute one gradient, and subsequent calls throw a runtime error. However, we can compute multiple gradients over the same computation by creating a ```persistent``` gradient tape. \n",
        "\n",
        "First, we will look at how we can compute gradients using GradientTape and access them for computation. We define the simple function $ y = x^2$ and compute the gradient:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdkqk8pw5yJM"
      },
      "outputs": [],
      "source": [
        "### Gradient computation with GradientTape ###\n",
        "\n",
        "# y = x^2\n",
        "# Example: x = 3.0\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "# Initiate the gradient tape\n",
        "with tf.GradientTape() as tape:\n",
        "  # Define the function\n",
        "  y = x * x\n",
        "# Access the gradient -- derivative of y with respect to x\n",
        "dy_dx = tape.gradient(y, x)\n",
        "\n",
        "assert dy_dx.numpy() == 6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhU5metS5xF3"
      },
      "source": [
        "In training neural networks, we use differentiation and stochastic gradient descent (SGD) to optimize a loss function. Now that we have a sense of how `GradientTape` can be used to compute and access derivatives, we will look at an example where we use automatic differentiation and SGD to find the minimum of $L=(x-x_f)^2$. Here $x_f$ is a variable for a desired value we are trying to optimize for; $L$ represents a loss that we are trying to  minimize. While we can clearly solve this problem analytically ($x_{min}=x_f$), considering how we can compute this using `GradientTape` sets us up nicely for future labs where we use gradient descent to optimize entire neural network losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "7g1yWiSXqEf-"
      },
      "outputs": [],
      "source": [
        "### Function minimization with automatic differentiation and SGD ###\n",
        "\n",
        "# Initialize a random value for our initial x\n",
        "x = tf.Variable([tf.random.normal([1])])\n",
        "print(\"Initializing x={}\".format(x.numpy()))\n",
        "\n",
        "learning_rate = 1e-2 # learning rate for SGD\n",
        "history = []\n",
        "# Define the target value\n",
        "x_f = 4\n",
        "\n",
        "# We will run SGD for a number of iterations. At each iteration, we compute the loss, \n",
        "#   compute the derivative of the loss with respect to x, and perform the SGD update.\n",
        "for i in range(500):\n",
        "  with tf.GradientTape() as tape:\n",
        "    '''TODO: define the loss as described above'''\n",
        "    loss = # TODO\n",
        "\n",
        "  # loss minimization using gradient tape\n",
        "  grad = tape.gradient(loss, x) # compute the derivative of the loss with respect to x\n",
        "  new_x = x - learning_rate*grad # sgd update\n",
        "  x.assign(new_x) # update the value of x\n",
        "  history.append(x.numpy()[0])\n",
        "\n",
        "# Plot the evolution of x as we optimize towards x_f!\n",
        "plt.plot(history)\n",
        "plt.plot([0, 500],[x_f,x_f])\n",
        "plt.legend(('Predicted', 'True'))\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('x value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC7czCwk3ceH"
      },
      "source": [
        "`GradientTape` provides an extremely flexible framework for automatic differentiation. In order to back propagate errors through a neural network, we track forward passes on the Tape, use this information to determine the gradients, and then use these gradients for optimization using SGD."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WBk0ZDWY-ff8"
      ],
      "name": "Part1_TensorFlow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('cs4321')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "9da4ff280c07e705865fb6db0cabb075c4eeb09216020ee5bcd173d7b53b0e0e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
